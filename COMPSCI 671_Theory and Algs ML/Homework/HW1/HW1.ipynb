{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL(P,Q) = 1.15\n",
      "KL(Q,P) = 1.36\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "p1 = 0.1\n",
    "p2 = 0.8\n",
    "\n",
    "#KL (P,Q)\n",
    "kl_p_q = p1 * math.log(p1/p2) + (1-p1) * math.log((1-p1)/(1-p2))\n",
    "txt = \"KL(P,Q) = {:0.2f}\".format(kl_p_q)\n",
    "print(txt)\n",
    "\n",
    "#KL(Q,P)\n",
    "kl_p_q = p2 * math.log(p2/p1) + (1-p2) * math.log((1-p2)/(1-p1))\n",
    "txt = \"KL(Q,P) = {:0.2f}\".format(kl_p_q)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem #3: Classifiers and Metrics - Coding\n",
    "### Support Code for Problem 3 (used throughout problem 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# storing the data in a numpy array with column labels as follows:\n",
    "# [\"Age\",\"likeRowing\",\"Experience\",\"Income\",\"Y\"]\n",
    "\n",
    "\n",
    "data = np.array([\n",
    "    [20,1,0,20,0,0],\n",
    "    [18,1,1,33,0,0],\n",
    "    [11,0,1,21,1,0],\n",
    "    [31,0,0,18,1,0],\n",
    "    [19,1,1,7,1,0],\n",
    "    [21,1,0,10,0,0],\n",
    "    [44,1,0,23,1,0],\n",
    "    [15,1,1,16,0,0],\n",
    "    [16,0,1,15,1,0],\n",
    "    [17,1,0,6,0,0]\n",
    "],dtype=np.double)\n",
    "\n",
    "\n",
    "\n",
    "def g_x(x = np.empty((4,1),dtype=np.double)):\n",
    "    #define theta and theta_0\n",
    "    theta = np.array([0.05,-3,2.1,0.008],dtype=np.double)\n",
    "    theta_0 = np.double(0.3)\n",
    "\n",
    "    #return g(x)\n",
    "    return np.matmul(np.transpose(theta),x) + theta_0\n",
    "\n",
    "def f_x(x = np.empty((4,1),dtype = np.double)):\n",
    "    return np.tanh(g_x(x))\n",
    "\n",
    "def compute_confusion_matrix(f_x,y,threshold = np.double(0.0)):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "\n",
    "    for i in range(0,f_x.size):\n",
    "        if y[i] == 1:\n",
    "            if f_x[i] >= threshold:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        else: #Y = 0\n",
    "            if f_x[i] < threshold:\n",
    "                TN += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "    \n",
    "    return np.array([[TP,FP],[FN,TN]])\n",
    "\n",
    "def print_confusion_matrix(cm):\n",
    "    df = pd.DataFrame({\"y = +1\":cm[:,0],\"y = 0\":cm[:,1]},\n",
    "        index = [\"f(x) >= threshold\",\"f(x) < threshold\"])\n",
    "    print(df)\n",
    "\n",
    "def compute_missclassification_error(cm):\n",
    "\n",
    "    FP = cm[0,1]\n",
    "    FN = cm[1,0]\n",
    "    TP = cm[0,0]\n",
    "    TN = cm[1,1]\n",
    "\n",
    "    return (FP + FN)/(FP + FN + TP + TN)\n",
    "\n",
    "def compute_true_positive_rate(cm):\n",
    "\n",
    "    TP = cm[0,0]\n",
    "    FN = cm[1,0]\n",
    "\n",
    "    return (TP) / (TP + FN)\n",
    "\n",
    "def compute_true_negative_rate(cm):\n",
    "\n",
    "    TN = cm[1,1]\n",
    "    FP = cm[0,1]\n",
    "\n",
    "    return (TN) / (TN + FP)\n",
    "\n",
    "def compute_false_positive_rate(cm):\n",
    "\n",
    "    FP = cm[0,1]\n",
    "    TN = cm[1,1]\n",
    "\n",
    "    return (FP) / (TN + FP)\n",
    "\n",
    "def compute_precision(cm):\n",
    "\n",
    "    TP = cm[0,0]\n",
    "    FP = cm[0,1]\n",
    "\n",
    "    return (TP) / (TP + FP)\n",
    "\n",
    "def compute_F1(cm):\n",
    "    \n",
    "    precision = compute_precision(cm)\n",
    "    recall = compute_true_positive_rate(cm)\n",
    "\n",
    "    return 2 * (precision * recall)/(precision + recall)\n",
    "\n",
    "def print_summary_statistics(f_x,y,threshold = 0):\n",
    "\n",
    "    #compute the confusion matrix:\n",
    "    cm = compute_confusion_matrix(f_x,y,threshold)\n",
    "\n",
    "    #Print confusion matrix\n",
    "    txt = \"Confusion Matrix:\"\n",
    "    print(txt)\n",
    "    print_confusion_matrix(cm)\n",
    "    \n",
    "    #Print missclassification error\n",
    "    txt = \"\\nMissclassification Error: {}\\n\".format(compute_missclassification_error(cm))\n",
    "    print(txt)\n",
    "\n",
    "    #Print Recall (TPR)\n",
    "    txt = \"Recall (TPR): {}\\n\".format(compute_true_positive_rate(cm))\n",
    "    print(txt)\n",
    "\n",
    "    #print Specificity (TNR)\n",
    "    txt = \"Specificity: {}\\n\".format(compute_true_negative_rate(cm))\n",
    "    print(txt)\n",
    "\n",
    "    #Print False Positive Rate\n",
    "    txt = \"False Positive Rate: {}\\n\".format(compute_false_positive_rate(cm))\n",
    "    print(txt)\n",
    "\n",
    "    #print Precision\n",
    "    txt = \"Precision: {}\\n\".format(compute_precision(cm))\n",
    "    print(txt)\n",
    "\n",
    "    #print F1\n",
    "    txt = \"F1: {}\\n\".format(compute_F1(cm))\n",
    "    print(txt)\n",
    "\n",
    "def generate_ROC_curve(f_x,y,show_plt = True):\n",
    "    \n",
    "    #put f_x and f_y into an array\n",
    "    data = np.array([y,f_x]).transpose()\n",
    "\n",
    "    #sort the array\n",
    "    data = data[(-1 * data[:,1]).argsort()]\n",
    "\n",
    "    #initialize an array of (FPR,TPR) coordinates for each threshold\n",
    "    ROC_points = np.empty((data.shape[0] + 2,2))\n",
    "\n",
    "    #initialize the first point\n",
    "    ROC_points[0,:] = [0,0]\n",
    "\n",
    "    #initialize the last point\n",
    "    ROC_points[11,:] = [1,1]\n",
    "\n",
    "    #for each threshold value\n",
    "    for i in range(0,data.shape[0]):\n",
    "\n",
    "        #compute the confusion matrix at the threshold\n",
    "        cm = compute_confusion_matrix(f_x,y,data[i,1])\n",
    "\n",
    "        #compute the FPR and TPR\n",
    "        TPR = compute_true_positive_rate(cm)\n",
    "        FPR = compute_false_positive_rate(cm)\n",
    "\n",
    "        #save the values in the array\n",
    "        ROC_points[i + 1,:] = [FPR,TPR]\n",
    "    \n",
    "    #plot the ROC curve\n",
    "    if show_plt:\n",
    "        plt.plot(ROC_points[:,0],ROC_points[:,1])\n",
    "        plt.xlabel(\"FPR\")\n",
    "        plt.ylabel(\"TPR\")\n",
    "        plt.title(\"ROC Curve\")\n",
    "        plt.show()\n",
    "    return ROC_points\n",
    "\n",
    "def plot_misclassification_vs_threshold(f_x,y,step_size = 0.1,show_plt = True):\n",
    "        #put f_x and f_y into an array\n",
    "    data = np.array([y,f_x]).transpose()\n",
    "\n",
    "    #sort the array\n",
    "    data = data[(-1 * data[:,1]).argsort()]\n",
    "\n",
    "    max_threshold = data[0,1] + 1\n",
    "    min_threshold = data[-1,1] - 1\n",
    "\n",
    "    #initialize an array to hold the plot points\n",
    "    thresholds_to_test = np.arange(min_threshold,max_threshold,step_size)\n",
    "\n",
    "    plt_points = np.empty((thresholds_to_test.shape[0],2))\n",
    "\n",
    "    #for each threshold value\n",
    "    for i in range(0,thresholds_to_test.shape[0]):\n",
    "\n",
    "        #compute the confusion matrix at the threshold\n",
    "        threshold = thresholds_to_test[i]\n",
    "        cm = compute_confusion_matrix(f_x,y,threshold)\n",
    "\n",
    "        #compute the FPR and TPR\n",
    "        miss_class_error = compute_missclassification_error(cm)\n",
    "\n",
    "        #save the values in the array\n",
    "        plt_points[i,:] = [threshold,miss_class_error]\n",
    "    \n",
    "    #plot the ROC curve\n",
    "    if show_plt:\n",
    "        plt.plot(plt_points[:,0],plt_points[:,1])\n",
    "        plt.xlabel(\"Threshold\")\n",
    "        plt.ylabel(\"Miss Classification Error\")\n",
    "        plt.title(\"Threshold vs Miss Classification Error\")\n",
    "        plt.show()\n",
    "    return plt_points\n",
    "\n",
    "def compute_g_x(data,print_output = True):\n",
    "    #compute g(x) for each x\n",
    "    for i in range(0,data.shape[0]):\n",
    "        data[i,5] = g_x(data[i,0:4])\n",
    "\n",
    "    if print_output:\n",
    "        df = pd.DataFrame({\"Age\":data[:,0],\n",
    "                            \"likeRowing\":data[:,1],\n",
    "                            \"Experience\":data[:,2],\n",
    "                            \"Income\":data[:,3],\n",
    "                            \"Y\":data[:,4],\n",
    "                            \"g(x)\":data[:,5]})\n",
    "        print(df)\n",
    "    return data\n",
    "\n",
    "def compute_f_x(data,print_output = True):\n",
    "    #compute g(x) for each x\n",
    "    for i in range(0,data.shape[0]):\n",
    "        data[i,5] = f_x(data[i,0:4])\n",
    "\n",
    "    if print_output:\n",
    "        df = pd.DataFrame({\"Age\":data[:,0],\n",
    "                            \"likeRowing\":data[:,1],\n",
    "                            \"Experience\":data[:,2],\n",
    "                            \"Income\":data[:,3],\n",
    "                            \"Y\":data[:,4],\n",
    "                            \"f(x)\":data[:,5]})\n",
    "        print(df)\n",
    "    return data\n",
    "\n",
    "def sort_output(data,f_x_col_idx,f_x_label = \"f(x)\",print_output = True):\n",
    "    #print a list sorted by the value of f_x\n",
    "    sorted_data = data[(-1 *data[:,f_x_col_idx]).argsort()]\n",
    "\n",
    "    if print_output:\n",
    "        df = pd.DataFrame({\"Age\":sorted_data[:,0],\n",
    "                            \"likeRowing\":sorted_data[:,1],\n",
    "                            \"Experience\":sorted_data[:,2],\n",
    "                            \"Income\":sorted_data[:,3],\n",
    "                            \"Y\":sorted_data[:,4],\n",
    "                            f_x_label:sorted_data[:,5]})\n",
    "        \n",
    "        print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.1\n",
    "\n",
    "Calculated Values of g(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  likeRowing  Experience  Income    Y   g(x)\n",
      "0  20.0         1.0         0.0    20.0  0.0 -1.540\n",
      "1  18.0         1.0         1.0    33.0  0.0  0.564\n",
      "2  11.0         0.0         1.0    21.0  1.0  3.118\n",
      "3  31.0         0.0         0.0    18.0  1.0  1.994\n",
      "4  19.0         1.0         1.0     7.0  1.0  0.406\n",
      "5  21.0         1.0         0.0    10.0  0.0 -1.570\n",
      "6  44.0         1.0         0.0    23.0  1.0 -0.316\n",
      "7  15.0         1.0         1.0    16.0  0.0  0.278\n",
      "8  16.0         0.0         1.0    15.0  1.0  3.320\n",
      "9  17.0         1.0         0.0     6.0  0.0 -1.802\n"
     ]
    }
   ],
   "source": [
    "g_x_computed = compute_g_x(data,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we determine what choise of threshold would minimize misclassification error. To do this, we can generate a plot of threshold vs miss-classification error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  likeRowing  Experience  Income    Y   g(x)\n",
      "0  16.0         0.0         1.0    15.0  1.0  3.320\n",
      "1  11.0         0.0         1.0    21.0  1.0  3.118\n",
      "2  31.0         0.0         0.0    18.0  1.0  1.994\n",
      "3  18.0         1.0         1.0    33.0  0.0  0.564\n",
      "4  19.0         1.0         1.0     7.0  1.0  0.406\n",
      "5  15.0         1.0         1.0    16.0  0.0  0.278\n",
      "6  44.0         1.0         0.0    23.0  1.0 -0.316\n",
      "7  20.0         1.0         0.0    20.0  0.0 -1.540\n",
      "8  21.0         1.0         0.0    10.0  0.0 -1.570\n",
      "9  17.0         1.0         0.0     6.0  0.0 -1.802\n"
     ]
    }
   ],
   "source": [
    "plt_points = plot_misclassification_vs_threshold(g_x_computed[:,5],g_x_computed[:,4],0.1)\n",
    "\n",
    "#print out a sorted list of g(x) as well\n",
    "sort_output(g_x_computed,5,\"g(x)\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this plot, it is clear that we can minimize misclassification error by putting the threshold in the following intervals: (-1.540,-.316),(0.278,0.406), and (0.564,1.994). Setting the threshold in any of these intervals gives us a missclassification error of 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.2\n",
    "\n",
    "Start by calculating the values of f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  likeRowing  Experience  Income    Y      f(x)\n",
      "0  20.0         1.0         0.0    20.0  0.0 -0.912120\n",
      "1  18.0         1.0         1.0    33.0  0.0  0.510939\n",
      "2  11.0         0.0         1.0    21.0  1.0  0.996092\n",
      "3  31.0         0.0         0.0    18.0  1.0  0.963601\n",
      "4  19.0         1.0         1.0     7.0  1.0  0.385071\n",
      "5  21.0         1.0         0.0    10.0  0.0 -0.917026\n",
      "6  44.0         1.0         0.0    23.0  1.0 -0.305886\n",
      "7  15.0         1.0         1.0    16.0  0.0  0.271053\n",
      "8  16.0         0.0         1.0    15.0  1.0  0.997389\n",
      "9  17.0         1.0         0.0     6.0  0.0 -0.947013\n"
     ]
    }
   ],
   "source": [
    "f_x_computed = compute_f_x(data,print_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we determine what choise of threshold would minimize misclassification error. To do this, we can generate a plot of threshold vs miss-classification error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  likeRowing  Experience  Income    Y      f(x)\n",
      "0  16.0         0.0         1.0    15.0  1.0  0.997389\n",
      "1  11.0         0.0         1.0    21.0  1.0  0.996092\n",
      "2  31.0         0.0         0.0    18.0  1.0  0.963601\n",
      "3  18.0         1.0         1.0    33.0  0.0  0.510939\n",
      "4  19.0         1.0         1.0     7.0  1.0  0.385071\n",
      "5  15.0         1.0         1.0    16.0  0.0  0.271053\n",
      "6  44.0         1.0         0.0    23.0  1.0 -0.305886\n",
      "7  20.0         1.0         0.0    20.0  0.0 -0.912120\n",
      "8  21.0         1.0         0.0    10.0  0.0 -0.917026\n",
      "9  17.0         1.0         0.0     6.0  0.0 -0.947013\n"
     ]
    }
   ],
   "source": [
    "plt_points = plot_misclassification_vs_threshold(f_x_computed[:,5],f_x_computed[:,4],0.01)\n",
    "\n",
    "#print out a sorted list of g(x) as well\n",
    "sort_output(f_x_computed,5,\"f(x)\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this plot, it is clear that we can minimize misclassification error by putting the threshold in the following intervals: (-0.912,-0.305),(0.271,0.385), and (0.51,0.96). Setting the threshold in any of these intervals gives us a missclassification error of 0.2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the confusion matrix, precision, recall, and F1 score for the threshold from (0.51,0.96) using a threshold of 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                   y = +1  y = 0\n",
      "f(x) >= threshold       3      0\n",
      "f(x) < threshold        2      5\n",
      "\n",
      "Missclassification Error: 0.2\n",
      "\n",
      "Recall (TPR): 0.6\n",
      "\n",
      "Specificity: 1.0\n",
      "\n",
      "False Positive Rate: 0.0\n",
      "\n",
      "Precision: 1.0\n",
      "\n",
      "F1: 0.7499999999999999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#compute relevant statistics for threshold of 0.6\n",
    "print_summary_statistics(f_x_computed[:,5],f_x_computed[:,4],threshold= 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.3\n",
    "\n",
    "Plot the ROC curves with additional points for decision points with minimum classification error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ROC_points = generate_ROC_curve(f_x_computed[:,5],f_x_computed[:,4],show_plt= False)\n",
    "\n",
    "#using the FPR and TPR from the points in the ranges computed above\n",
    "decision_points = np.array([[0,0.6],[0.2,0.8],[0.4,1.0]])\n",
    "plt.plot(ROC_points[:,0],ROC_points[:,1],\"b-\",decision_points[:,0],decision_points[:,1],\"ro\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.title(\"ROC Curve with Decision Points\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information gain with Gini: \n",
      "\tSplit on A: 0.28125 \n",
      "\tSplit on B: 0.03125 \n",
      "\tSplit on C: 0.03125\n",
      "Information gain with Entropy: \n",
      "\tSplit on A: 0.5487949406953985 \n",
      "\tSplit on B: 0.04879494069539847 \n",
      "\tSplit on C: 0.04879494069539847\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def Gini(p):\n",
    "    return 2 * p * (1 - p)\n",
    "\n",
    "def H(p):\n",
    "    if p == 0 or p == 1:\n",
    "        return -1 * p * math.log(1,2)\n",
    "    else:\n",
    "        return -1 * p * math.log(p,2) - (1-p) * math.log(1-p,2)\n",
    "\n",
    "#using Gini Index\n",
    "Gini(1)\n",
    "gain_A = Gini(5/8) - (4/8 * Gini(4/4) + 4/8 * Gini(1/4))\n",
    "gain_B = Gini(5/8) - (4/8 * Gini(3/4) + 4/8 * Gini(2/4))\n",
    "gain_C = Gini(5/8) - (4/8 * Gini(3/4) + 4/8 * Gini(2/4))\n",
    "\n",
    "txt = \"Information gain with Gini: \\n\\tSplit on A: {} \\n\\tSplit on B: {} \\n\\tSplit on C: {}\".format(gain_A,gain_B,gain_C)\n",
    "print(txt)\n",
    "\n",
    "#using entropy\n",
    "gain_A = H(5/8) - (4/8 * H(4/4) + 4/8 * H(1/4))\n",
    "gain_B = H(5/8) - (4/8 * H(3/4) + 4/8 * H(2/4))\n",
    "gain_C = H(5/8) - (4/8 * H(3/4) + 4/8 * H(2/4))\n",
    "\n",
    "txt = \"Information gain with Entropy: \\n\\tSplit on A: {} \\n\\tSplit on B: {} \\n\\tSplit on C: {}\".format(gain_A,gain_B,gain_C)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to Support importing and exporting of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def import_and_format_data(csv,print_preview = True):\n",
    "    data = pd.read_csv(csv)\n",
    "\n",
    "    #convert ShelveLoc to be numerical\n",
    "    d = {\"Bad\":0,\"Medium\":1,\"Good\":2}\n",
    "    data[\"ShelveLoc\"] = data[\"ShelveLoc\"].map(d)\n",
    "\n",
    "    #convert urban and US to numerical\n",
    "    d = {\"Yes\":0,\"No\":1}\n",
    "    data[\"Urban\"] = data[\"Urban\"].map(d)\n",
    "    data[\"US\"] = data[\"US\"].map(d)\n",
    "\n",
    "    if print_preview:\n",
    "        print(data)\n",
    "    return data\n",
    "\n",
    "def compute_normalization_constants(data, print_preview = True):\n",
    "\n",
    "    normalization_constants = np.zeros((3,data.shape[1]))\n",
    "    cols = data.columns\n",
    "    indicies = [\"min\",\"max\",\"range\"]\n",
    "\n",
    "    #for each row in the data\n",
    "    for i in range(0,cols.size):\n",
    "        #get vals from teh column\n",
    "        vals = data.iloc[:,i].to_numpy()\n",
    "\n",
    "        #determine min,max, and range\n",
    "        max_val = vals.max()\n",
    "        min_val = vals.min()\n",
    "        range_val = max_val - min_val\n",
    "        \n",
    "        #save in the normalization constants array\n",
    "        normalization_constants[:,i] = np.array([min_val,max_val,range_val]).transpose()\n",
    "\n",
    "    #return the normalization constants\n",
    "    norm_constants = pd.DataFrame(normalization_constants,columns=cols,index=indicies)\n",
    "\n",
    "    if print_preview:\n",
    "        print(norm_constants)\n",
    "    return norm_constants\n",
    "\n",
    "def normalize_data(data,normalization_constants,print_preview = True):\n",
    "\n",
    "    normed_vals = np.zeros(data.shape)\n",
    "\n",
    "    #for each column in data, normalize using the normalization constants\n",
    "    for i in range(0,data.columns.size):\n",
    "        vals = data.iloc[:,i].to_numpy()\n",
    "        min_val = normalization_constants.iloc[0,i]\n",
    "        range_val = normalization_constants.iloc[2,i]\n",
    "        \n",
    "        #normalize the data\n",
    "        vals = np.subtract(vals,min_val)\n",
    "        vals = np.divide(vals,range_val)\n",
    "\n",
    "        #save it in the data array\n",
    "        normed_vals[:,i] = vals\n",
    "    \n",
    "    normalized_values = pd.DataFrame(normed_vals,columns= data.columns)\n",
    "\n",
    "    if print_preview:\n",
    "        print(normalized_values)\n",
    "\n",
    "    return normalized_values\n",
    "\n",
    "def divide_into_folds(data,num_folds):\n",
    "    num_rows = data.shape[0]\n",
    "    rows_per_fold = math.floor(num_rows/num_folds)\n",
    "\n",
    "    folds = deque()\n",
    "\n",
    "    #create all folds except for the last one\n",
    "    for i in range(0,num_folds - 1):\n",
    "        start_idx = rows_per_fold * i\n",
    "        end_idx = rows_per_fold * (i + 1)\n",
    "        fold = pd.DataFrame(data.iloc[start_idx:end_idx,:])\n",
    "        folds.append(fold)\n",
    "    \n",
    "    #push the final \n",
    "    start_idx = rows_per_fold * (num_folds - 1)\n",
    "    folds.append(data.iloc[start_idx:,:])\n",
    "\n",
    "    return folds\n",
    "\n",
    "def initialize_validation_tracking(validation_rounds,params_to_test):\n",
    "\n",
    "    data = {}\n",
    "    for i in range(0,params_to_test.shape[0]):\n",
    "        key = str(params_to_test[i])\n",
    "        data[key] = np.zeros(validation_rounds,dtype= np.double)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def compute_mean_evaluation_metric(measure_results,params_to_test,test_metric = \"\"):\n",
    "\n",
    "    #declare an empty array to track the mean results\n",
    "    mean_results = np.zeros(params_to_test.shape[0],dtype= np.double)\n",
    "\n",
    "    #declare array to track best parameter\n",
    "    best_mean_result = 0\n",
    "    best_param = params_to_test[0]\n",
    "\n",
    "    for i in range(0,params_to_test.shape[0]):\n",
    "\n",
    "        #get the results for the specific parameter\n",
    "        key = str(params_to_test[i])\n",
    "        results = measure_results[key].to_numpy()\n",
    "        mean = np.mean(results)\n",
    "        mean_results[i] = mean\n",
    "\n",
    "        #check if this is the best one\n",
    "        if mean > best_mean_result or i == 0:\n",
    "            best_mean_result = mean\n",
    "            best_param = params_to_test[i]\n",
    "    \n",
    "    #create a DataFrame for the evaluation metrics\n",
    "    result_summary = pd.DataFrame(np.array([mean_results]),columns=measure_results.columns,\n",
    "     index=[test_metric])\n",
    "\n",
    "    return result_summary,best_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Using Decision Trees\n",
    "\n",
    "#### SKLEARN code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training with sklearn\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import math\n",
    "\n",
    "def train_with_sklearn(X,Y,features,max_depth = 5,plot_tree = True):\n",
    "    dtree = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    dtree = dtree.fit(X,Y)\n",
    "\n",
    "    if plot_tree:\n",
    "        tree.plot_tree(dtree,feature_names= features)\n",
    "    return dtree\n",
    "\n",
    "def test_sklearn(dtree,X_test,Y_test,print_results = False):\n",
    "    f_x = dtree.predict(X_test)\n",
    "\n",
    "    cm = compute_confusion_matrix(f_x,Y_test,threshold= 0.5)\n",
    "\n",
    "    f1 = compute_F1(cm)\n",
    "    accuracy = 1 - compute_missclassification_error(cm)\n",
    "\n",
    "    if print_results:\n",
    "        print_summary_statistics(f_x,Y_test,threshold=0.5)\n",
    "    \n",
    "    return f1,accuracy\n",
    "\n",
    "def k_fold_sklearn(data,depths_to_test,num_folds):\n",
    "    #split data into folds\n",
    "    folds = divide_into_folds(data,num_folds)\n",
    "\n",
    "    #set asside test fold\n",
    "    test_fold = folds.pop()\n",
    "\n",
    "    #initialize variables for performing cross validation\n",
    "    validation_rounds = num_folds - 1\n",
    "    measure_results = initialize_validation_tracking(validation_rounds,depths_to_test)\n",
    "    features = data.columns[1:]\n",
    "\n",
    "    for round_idx in range(0,validation_rounds):\n",
    "        #reserve a validation set from the training set\n",
    "        validation_fold = folds.popleft()\n",
    "        training_sets = pd.concat(folds)\n",
    "\n",
    "        #identify inputs and outputs for training\n",
    "        X_train = pd.DataFrame(training_sets.iloc[:,1:])\n",
    "        Y_train = pd.DataFrame(training_sets.iloc[:,0])\n",
    "\n",
    "        #identify inputs and outputs for validation\n",
    "        X_validation = pd.DataFrame(validation_fold.iloc[:,1:])\n",
    "        Y_validation = pd.DataFrame(validation_fold.iloc[:,0])\n",
    "\n",
    "        #train algorithm on the rest of the training set for each K, evaluate on validation set\n",
    "        for depth_idx in range(0,depths_to_test.size):\n",
    "            depth = depths_to_test[depth_idx]\n",
    "\n",
    "            #train the algorithm\n",
    "            dtree = train_with_sklearn(X_train,Y_train,features,max_depth=depth,plot_tree=False)\n",
    "\n",
    "            #evaluate on validation set\n",
    "            f1,accuracy = test_sklearn(dtree,X_validation,Y_validation.to_numpy(),print_results=False)\n",
    "\n",
    "            #record validation metric\n",
    "            measure_results.iat[round_idx,depth_idx] = f1\n",
    "\n",
    "        #rotate validation fold and repeat\n",
    "        folds.append(validation_fold)\n",
    "\n",
    "    #report mean of evaluation measure for each K over the validation folds\n",
    "    result_summary,best_param = compute_mean_evaluation_metric(measure_results,depths_to_test,\"F1\")\n",
    "\n",
    "    txt = \"Mean results (average F1 score) of K-fold cross validation on {} folds \\n {}\".format(num_folds,result_summary)\n",
    "    print(txt)\n",
    "    #choose the best K\n",
    "\n",
    "    txt = \"Training on depth of {}\\n\".format(best_param)\n",
    "    print(txt)\n",
    "    \n",
    "    #train on the full training set, evaluate on the test set\n",
    "    training_set = pd.concat(folds)\n",
    "    X_train = pd.DataFrame(training_set.iloc[:,1:])\n",
    "    Y_train = pd.DataFrame(training_set.iloc[:,0])\n",
    "    dtree = train_with_sklearn(X_train,Y_train,features,max_depth=best_param,plot_tree=True)\n",
    "\n",
    "    \n",
    "    X_test = pd.DataFrame(test_fold.iloc[:,1:])\n",
    "    Y_test = pd.DataFrame(test_fold.iloc[:,0])\n",
    "\n",
    "    #evaluate on testing set\n",
    "    f1,accuracy = test_sklearn(dtree,X_test,Y_test.to_numpy(),print_results=False)\n",
    "    txt = \"\\nResults on testing fold:\\n \\tF1: {:0.2f}\\n \\tAccuracy: {:0.2f}\".format(f1,accuracy)\n",
    "    print(txt)\n",
    "\n",
    "    #return the final model\n",
    "    return dtree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean results (average F1 score) of K-fold cross validation on 5 folds \n",
      "            3         4         5         6         7\n",
      "F1  0.520261  0.559441  0.571682  0.555721  0.602564\n",
      "Training on depth of 7\n",
      "\n",
      "\n",
      "Results on testing fold:\n",
      " \tF1: 0.60\n",
      " \tAccuracy: 0.59\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#run cross validation using sklearn and obtain a final model\n",
    "\n",
    "data_train = import_and_format_data(\"carseats_train.csv\",print_preview= False)\n",
    "depths_to_test = np.array([3,4,5,6,7])\n",
    "\n",
    "dtree = k_fold_sklearn(data_train,depths_to_test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results on actual testing data:\n",
      " \tF1: 0.74\n",
      " \tAccuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "# determine the full accuracy of the model using the supplied test data file\n",
    "data_test = import_and_format_data(\"carseats_test.csv\",print_preview=False)\n",
    "\n",
    "X_test = pd.DataFrame(data_test.iloc[:,1:])\n",
    "Y_test = pd.DataFrame(data_test.iloc[:,0])\n",
    "\n",
    "#evaluate on testing set\n",
    "f1,accuracy = test_sklearn(dtree,X_test,Y_test.to_numpy(),print_results=False)\n",
    "txt = \"\\nResults on actual testing data:\\n \\tF1: {:0.2f}\\n \\tAccuracy: {:0.2f}\".format(f1,accuracy)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees with GODST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train with GODST\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gosdt.model.threshold_guess import compute_thresholds, cut\n",
    "from gosdt.model.gosdt import GOSDT\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import time\n",
    "\n",
    "\n",
    "def config_GOSDT_data(data_train,data_test):\n",
    "\n",
    "    #set asside the X and Y for training\n",
    "    X = pd.DataFrame(data_train.iloc[:,1:])\n",
    "    Y = pd.DataFrame(data_train.iloc[:,0])\n",
    "\n",
    "    #set asside X and Y for testing\n",
    "    X_test = pd.DataFrame(data_test.iloc[:,1:])\n",
    "    Y_test = pd.DataFrame(data_test.iloc[:,0])\n",
    "\n",
    "    #leverage the GHOST example code to guess thresholds and lower bounds to improve performance\n",
    "\n",
    "    h = X.columns\n",
    "\n",
    "    # GBDT parameters for threshold and lower bound guesses\n",
    "    n_est = 40\n",
    "    max_depth = 1\n",
    "\n",
    "    # guess thresholds\n",
    "    X = pd.DataFrame(X, columns=h)\n",
    "    print(\"X:\", X.shape)\n",
    "    print(\"y:\",Y.shape)\n",
    "    X_train, thresholds, header, threshold_guess_time = compute_thresholds(X, Y, n_est, max_depth)\n",
    "\n",
    "    #configure X_test as well\n",
    "    X_test = cut(X_test.copy(),thresholds)\n",
    "    X_test = X_test[header]\n",
    "\n",
    "    #print(X_train.shape)\n",
    "    #print(X_test.shape)\n",
    "    \n",
    "    txt = \"train set column names == test set column names: {}\".format(list(X_train.columns) == \n",
    "        list(X_test.columns))\n",
    "    print(txt)\n",
    "\n",
    "    Y_train = pd.DataFrame(Y)\n",
    "\n",
    "    # guess lower bound\n",
    "    start_time = time.perf_counter()\n",
    "    clf = GradientBoostingClassifier(n_estimators=n_est, max_depth=max_depth, random_state=42)\n",
    "    clf.fit(X_train, Y_train.values.flatten())\n",
    "    warm_labels = clf.predict(X_train)\n",
    "\n",
    "    elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "    lb_time = elapsed_time\n",
    "\n",
    "    # save the labels as a tmp file and return the path to it.\n",
    "    labelsdir = pathlib.Path('/tmp/warm_lb_labels')\n",
    "    labelsdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    labelpath = labelsdir / 'warm_label.tmp'\n",
    "    labelpath = str(labelpath)\n",
    "    pd.DataFrame(warm_labels, columns=[\"class_labels\"]).to_csv(labelpath, header=\"class_labels\",index=None)\n",
    "\n",
    "    return X_train,Y_train, X_test, Y_test, labelpath\n",
    "\n",
    "def train_GOSDT_model(X,Y,labelpath,depth_budget = 5,regularization = 0.01):\n",
    "    # train GOSDT model\n",
    "    config = {\n",
    "                \"allow_small_reg\": True,\n",
    "                \"regularization\": regularization,\n",
    "                \"depth_budget\": depth_budget,\n",
    "                \"time_limit\": 60,\n",
    "                \"warm_LB\": True,\n",
    "                \"path_to_labels\": labelpath,\n",
    "                \"similar_support\": False,\n",
    "            }\n",
    "\n",
    "    model = GOSDT(config)\n",
    "    model.fit(X, Y)\n",
    "\n",
    "    return model\n",
    "\n",
    "def test_GOSDT(model,X_test,Y_test,print_results = False):\n",
    "    f_x = model.predict(X_test)\n",
    "\n",
    "    cm = compute_confusion_matrix(f_x,Y_test,threshold= 0.5)\n",
    "\n",
    "    f1 = compute_F1(cm)\n",
    "    accuracy = 1 - compute_missclassification_error(cm)\n",
    "\n",
    "    if print_results:\n",
    "        print_summary_statistics(f_x,Y_test,threshold=0.5)\n",
    "    \n",
    "    return f1,accuracy\n",
    "\n",
    "def print_GOSDT_summary(model,X_train,Y_train):\n",
    "    print(\"evaluate the model, extracting tree and scores\", flush=True)\n",
    "\n",
    "    # get the results\n",
    "    train_acc = model.score(X_train, Y_train)\n",
    "    n_leaves = model.leaves()\n",
    "    n_nodes = model.nodes()\n",
    "    time = model.utime\n",
    "\n",
    "    print(\"Model training time: {}\".format(time))\n",
    "    print(\"Training accuracy: {}\".format(train_acc))\n",
    "    print(\"# of leaves: {}\".format(n_leaves))\n",
    "    print(model.tree)\n",
    "\n",
    "def k_fold_GOSDT(X_train,Y_train,labelpath,regularizations_to_test,num_folds):\n",
    "    #since GOSDT prints a lot of stuff as is, save all prints to a variable and return it as output\n",
    "    out_txt = \"\"\n",
    "    \n",
    "    #split data into folds\n",
    "    X_folds = divide_into_folds(X_train,num_folds)\n",
    "    Y_folds = divide_into_folds(Y_train,num_folds)\n",
    "\n",
    "    #set asside test fold\n",
    "    X_test = X_folds.pop()\n",
    "    Y_test = Y_folds.pop()\n",
    "\n",
    "    #initialize variables for performing cross validation\n",
    "    validation_rounds = num_folds - 1\n",
    "    measure_results = initialize_validation_tracking(validation_rounds,regularizations_to_test)\n",
    "    features = X_train.columns\n",
    "\n",
    "    for round_idx in range(0,validation_rounds):\n",
    "        #reserve a validation set from the training set\n",
    "        X_validation = X_folds.popleft()\n",
    "        Y_validation = Y_folds.popleft()\n",
    "\n",
    "        X_train = pd.DataFrame(pd.concat(X_folds))\n",
    "        Y_train = pd.DataFrame(pd.concat(Y_folds))\n",
    "\n",
    "        #train algorithm on the rest of the training set for each K, evaluate on validation set\n",
    "        for reg_idx in range(0,regularizations_to_test.size):\n",
    "            reg = regularizations_to_test[reg_idx]\n",
    "\n",
    "            #train the algorithm\n",
    "            model = train_GOSDT_model(X_train,Y_train,labelpath,depth_budget=6,regularization=reg)\n",
    "\n",
    "            #evaluate on validation set\n",
    "            f1,accuracy = test_GOSDT(model,X_validation,Y_validation.to_numpy(),print_results=False)\n",
    "\n",
    "            #record validation metric\n",
    "            measure_results.iat[round_idx,reg_idx] = f1\n",
    "\n",
    "        #rotate validation fold and repeat\n",
    "        X_folds.append(X_validation)\n",
    "        Y_folds.append(Y_validation)\n",
    "\n",
    "    #report mean of evaluation measure for each K over the validation folds\n",
    "    result_summary,best_param = compute_mean_evaluation_metric(measure_results,regularizations_to_test,\"F1\")\n",
    "\n",
    "    txt = \"Mean results (average F1 score) of K-fold cross validation on {} folds \\n {}\\n\".format(num_folds,result_summary)\n",
    "    print(txt)\n",
    "    out_txt = out_txt + txt\n",
    "    #choose the best K\n",
    "\n",
    "    txt = \"Training on depth of {}\\n\".format(best_param)\n",
    "    print(txt)\n",
    "    out_txt = out_txt + txt\n",
    "    \n",
    "    #train on the full training set, evaluate on the test set\n",
    "    X_train = pd.DataFrame(pd.concat(X_folds))\n",
    "    Y_train = pd.DataFrame(pd.concat(Y_folds))\n",
    "    model = train_GOSDT_model(X_train,Y_train,labelpath,depth_budget=5,regularization=best_param)\n",
    "\n",
    "    #evaluate on testing set\n",
    "    f1,accuracy = test_GOSDT(model,X_test,Y_test.to_numpy(),print_results=False)\n",
    "    txt = \"\\nResults on testing fold:\\n \\tF1: {:0.2f}\\n \\tAccuracy: {:0.2f}\\n\".format(f1,accuracy)\n",
    "    print(txt)\n",
    "    out_txt = out_txt + txt\n",
    "\n",
    "    #return the final model\n",
    "    return model,out_txt\n",
    "\n",
    "def k_fold_GOSDT_alt(data_train,data_test,regularizations_to_test,num_folds):\n",
    "    #since GOSDT prints a lot of stuff as is, save all prints to a variable and return it as output\n",
    "    out_txt = \"\"\n",
    "    \n",
    "    #split data into folds\n",
    "    folds = divide_into_folds(data_train,num_folds)\n",
    "\n",
    "    #set asside test fold\n",
    "    test_fold = folds.pop()\n",
    "\n",
    "    #initialize variables for performing cross validation\n",
    "    validation_rounds = num_folds - 1\n",
    "    measure_results = initialize_validation_tracking(validation_rounds,regularizations_to_test)\n",
    "\n",
    "    for round_idx in range(0,validation_rounds):\n",
    "        #reserve a validation set from the training set\n",
    "        validation_fold = folds.popleft()\n",
    "        training_sets = pd.concat(folds)\n",
    "\n",
    "        X_train,Y_train, X_validation, Y_validation, labelpath = config_GOSDT_data(training_sets,validation_fold)\n",
    "\n",
    "        #train algorithm on the rest of the training set for each K, evaluate on validation set\n",
    "        for reg_idx in range(0,regularizations_to_test.size):\n",
    "            reg = regularizations_to_test[reg_idx]\n",
    "\n",
    "            #train the algorithm\n",
    "            model = train_GOSDT_model(X_train,Y_train,labelpath,depth_budget=6,regularization=reg)\n",
    "\n",
    "            #evaluate on validation set\n",
    "            f1,accuracy = f1,accuracy = test_GOSDT(model,X_validation,Y_validation.to_numpy(),print_results=False)\n",
    "\n",
    "            #record validation metric\n",
    "            measure_results.iat[round_idx,reg_idx] = f1\n",
    "\n",
    "        #rotate validation fold and repeat\n",
    "        folds.append(validation_fold)\n",
    "\n",
    "    #report mean of evaluation measure for each K over the validation folds\n",
    "    result_summary,best_param = compute_mean_evaluation_metric(measure_results,regularizations_to_test,\"F1\")\n",
    "\n",
    "    txt = \"Mean results (average F1 score) of K-fold cross validation on {} folds \\n {}\\n\".format(num_folds,result_summary)\n",
    "    print(txt)\n",
    "    out_txt = out_txt + txt\n",
    "    #choose the best K\n",
    "\n",
    "    txt = \"Training on regularization of {}\\n\".format(best_param)\n",
    "    print(txt)\n",
    "    out_txt = out_txt + txt\n",
    "    \n",
    "    #train on the full training set, evaluate on the test set\n",
    "    training_set = pd.concat(folds)\n",
    "    X_train,Y_train, X_test, Y_test, labelpath = config_GOSDT_data(training_sets,test_fold)\n",
    "    #train the algorithm\n",
    "    model = train_GOSDT_model(X_train,Y_train,labelpath,depth_budget=6,regularization=best_param)\n",
    "\n",
    "    #evaluate on validation set\n",
    "    f1,accuracy = f1,accuracy = test_GOSDT(model,X_test,Y_test.to_numpy(),print_results=False)\n",
    "\n",
    "    #evaluate on testing set\n",
    "    txt = \"\\nResults on testing fold:\\n \\tF1: {:0.2f}\\n \\tAccuracy: {:0.2f}\".format(f1,accuracy)\n",
    "    print(txt)\n",
    "    out_txt = out_txt + txt\n",
    "\n",
    "    #since there is another full testing set, reformat the actual testing data file so it can be used in testing\n",
    "    #train on the full training data file\n",
    "    training_set = pd.concat(folds)\n",
    "    X_train,Y_train, X_test, Y_test, labelpath = config_GOSDT_data(data_train,data_test)\n",
    "    #train the algorithm\n",
    "    model = train_GOSDT_model(X_train,Y_train,labelpath,depth_budget=6,regularization=best_param)\n",
    "\n",
    "    #return the final model\n",
    "    return model,out_txt,X_train,Y_train,X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (282, 10)\n",
      "y: (282, 1)\n",
      "train set column names == test set column names: True\n",
      "X: (168, 10)\n",
      "y: (168, 1)\n",
      "train set column names == test set column names: True\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.014 (user, system, wall), mem=0 MB\n",
      "bounds: [0.214762..0.214762] (0.000000) loss=0.154762, iterations=2410\n",
      "gosdt reported successful executionRegularization smaller than 1/(num_samples) - this may lead to longer training time if not adjusted.\n",
      "\n",
      "training completed. 0.000/0.000/0.029 (user, system, wall), mem=0 MB\n",
      "bounds: [0.140952..0.140952] (0.000000) loss=0.130952, iterations=4870\n",
      "Regularization smaller than 1/(num_samples) - this may lead to longer training time if not adjusted.\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.030 (user, system, wall), mem=0 MB\n",
      "bounds: [0.135952..0.135952] (0.000000) loss=0.130952, iterations=4871\n",
      "X: (168, 10)\n",
      "y: (168, 1)\n",
      "train set column names == test set column names: True\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.005 (user, system, wall), mem=0 MB\n",
      "bounds: [0.225000..0.225000] (0.000000) loss=0.125000, iterations=1302\n",
      "Regularization smaller than 1/(num_samples) - this may lead to longer training time if not adjusted.\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.008 (user, system, wall), mem=0 MB\n",
      "bounds: [0.153857..0.153857] (0.000000) loss=0.142857, iterations=1552\n",
      "Regularization smaller than 1/(num_samples) - this may lead to longer training time if not adjusted.\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.006 (user, system, wall), mem=0 MB\n",
      "bounds: [0.153310..0.153310] (0.000000) loss=0.148810, iterations=1174\n",
      "X: (168, 10)\n",
      "y: (168, 1)\n",
      "train set column names == test set column names: True\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.004 (user, system, wall), mem=0 MB\n",
      "bounds: [0.210952..0.210952] (0.000000) loss=0.130952, iterations=1015\n",
      "Regularization smaller than 1/(num_samples) - this may lead to longer training time if not adjusted.\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.006 (user, system, wall), mem=0 MB\n",
      "bounds: [0.125095..0.125095] (0.000000) loss=0.113095, iterations=1432\n",
      "Regularization smaller than 1/(num_samples) - this may lead to longer training time if not adjusted.\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.006 (user, system, wall), mem=0 MB\n",
      "bounds: [0.119095..0.119095] (0.000000) loss=0.113095, iterations=1440\n",
      "X: (168, 10)\n",
      "y: (168, 1)\n",
      "train set column names == test set column names: True\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.074 (user, system, wall), mem=0 MB\n",
      "bounds: [0.196905..0.196905] (0.000000) loss=0.136905, iterations=10098\n",
      "gosdt reported successful executionRegularization smaller than 1/(num_samples) - this may lead to longer training time if not adjusted.\n",
      "training completed. 0.000/0.000/0.117 (user, system, wall), mem=0 MB\n",
      "bounds: [0.128048..0.128048] (0.000000) loss=0.119048, iterations=13074\n",
      "\n",
      "gosdt reported successful executionRegularization smaller than 1/(num_samples) - this may lead to longer training time if not adjusted.\n",
      "\n",
      "training completed. 0.000/0.000/0.118 (user, system, wall), mem=0 MB\n",
      "bounds: [0.123548..0.123548] (0.000000) loss=0.119048, iterations=13141\n",
      "Mean results (average F1 score) of K-fold cross validation on 5 folds \n",
      "         0.01     0.001    0.0005\n",
      "F1  0.565304  0.543164  0.576646\n",
      "\n",
      "Training on regularization of 0.0005\n",
      "\n",
      "X: (168, 10)\n",
      "y: (168, 1)\n",
      "train set column names == test set column names: True\n",
      "Regularization smaller than 1/(num_samples) - this may lead to longer training time if not adjusted.\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.120 (user, system, wall), mem=0 MB\n",
      "bounds: [0.123548..0.123548] (0.000000) loss=0.119048, iterations=13141\n",
      "\n",
      "Results on testing fold:\n",
      " \tF1: 0.71\n",
      " \tAccuracy: 0.74\n",
      "X: (282, 10)\n",
      "y: (282, 1)\n",
      "train set column names == test set column names: True\n",
      "Regularization smaller than 1/(num_samples) - this may lead to longer training time if not adjusted.\n",
      "gosdt reported successful execution\n",
      "training completed. 0.000/0.000/0.034 (user, system, wall), mem=0 MB\n",
      "bounds: [0.165574..0.165574] (0.000000) loss=0.159574, iterations=5308\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_train = import_and_format_data(\"carseats_train.csv\",print_preview= False)\n",
    "data_test = import_and_format_data(\"carseats_test.csv\",print_preview=False)\n",
    "\n",
    "X_train,Y_train, X_test, Y_test, labelpath = config_GOSDT_data(data_train,data_test)\n",
    "\n",
    "regularizations_to_test = np.array([0.01,0.001,0.0005])\n",
    "\n",
    "model,out_txt,X_train,Y_train,X_test, Y_test = k_fold_GOSDT_alt(data_train,data_test,regularizations_to_test,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean results (average F1 score) of K-fold cross validation on 5 folds \n",
      "         0.01     0.001    0.0005\n",
      "F1  0.565304  0.543164  0.576646\n",
      "Training on regularization of 0.0005\n",
      "\n",
      "Results on testing fold:\n",
      " \tF1: 0.71\n",
      " \tAccuracy: 0.74\n",
      "After testing on actual test set, results are as follows: \n",
      "\tF1:0.7543859649122807\n",
      "\tAccuracy:0.7627118644067796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(out_txt)\n",
    "\n",
    "f1,accuracy = test_GOSDT(model,X_test,Y_test.to_numpy(),print_results=False)\n",
    "txt = \"After testing on actual test set, results are as follows: \\n\\tF1:{}\\n\\tAccuracy:{}\\n\".format(f1,accuracy)\n",
    "print(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate the model, extracting tree and scores\n",
      "Model training time: 0.0\n",
      "Training accuracy: 0.8404255319148937\n",
      "# of leaves: 12\n",
      "if Age<=60.5 = 1 and Price<=106.5 = 1 and ShelveLoc<=0.5 = 1 then:\n",
      "    predicted class: 0\n",
      "    misclassification penalty: 0.014\n",
      "    complexity penalty: 0.001\n",
      "\n",
      "else if Age<=60.5 = 1 and Price<=106.5 = 1 and ShelveLoc<=0.5 != 1 then:\n",
      "    predicted class: 1\n",
      "    misclassification penalty: 0.018\n",
      "    complexity penalty: 0.001\n",
      "\n",
      "else if Advertising<=8.5 = 1 and Age<=60.5 = 1 and Income<=60.5 = 1 and Price<=106.5 != 1 then:\n",
      "    predicted class: 0\n",
      "    misclassification penalty: 0.014\n",
      "    complexity penalty: 0.001\n",
      "\n",
      "else if Advertising<=8.5 != 1 and Age<=60.5 = 1 and Income<=60.5 = 1 and Price<=106.5 != 1 and ShelveLoc<=1.5 = 1 then:\n",
      "    predicted class: 0\n",
      "    misclassification penalty: 0.007\n",
      "    complexity penalty: 0.001\n",
      "\n",
      "else if Advertising<=8.5 != 1 and Age<=60.5 = 1 and Income<=60.5 = 1 and Price<=106.5 != 1 and ShelveLoc<=1.5 != 1 then:\n",
      "    predicted class: 1\n",
      "    misclassification penalty: 0.0\n",
      "    complexity penalty: 0.001\n",
      "\n",
      "else if Age<=60.5 = 1 and Income<=60.5 != 1 and Price<=106.5 != 1 and Price<=127.5 = 1 then:\n",
      "    predicted class: 1\n",
      "    misclassification penalty: 0.035\n",
      "    complexity penalty: 0.001\n",
      "\n",
      "else if Age<=60.5 = 1 and Income<=60.5 != 1 and Price<=106.5 != 1 and Price<=127.5 != 1 and ShelveLoc<=1.5 = 1 then:\n",
      "    predicted class: 0\n",
      "    misclassification penalty: 0.007\n",
      "    complexity penalty: 0.001\n",
      "\n",
      "else if Age<=60.5 = 1 and Income<=60.5 != 1 and Price<=106.5 != 1 and Price<=127.5 != 1 and ShelveLoc<=1.5 != 1 then:\n",
      "    predicted class: 1\n",
      "    misclassification penalty: 0.007\n",
      "    complexity penalty: 0.001\n",
      "\n",
      "else if Age<=60.5 != 1 and Price<=92.5 = 1 and ShelveLoc<=1.5 = 1 then:\n",
      "    predicted class: 1\n",
      "    misclassification penalty: 0.021\n",
      "    complexity penalty: 0.001\n",
      "\n",
      "else if Age<=60.5 != 1 and Price<=92.5 != 1 and ShelveLoc<=1.5 = 1 then:\n",
      "    predicted class: 0\n",
      "    misclassification penalty: 0.028\n",
      "    complexity penalty: 0.001\n",
      "\n",
      "else if Age<=60.5 != 1 and Price<=127.5 = 1 and ShelveLoc<=1.5 != 1 then:\n",
      "    predicted class: 1\n",
      "    misclassification penalty: 0.004\n",
      "    complexity penalty: 0.001\n",
      "\n",
      "else if Age<=60.5 != 1 and Price<=127.5 != 1 and ShelveLoc<=1.5 != 1 then:\n",
      "    predicted class: 0\n",
      "    misclassification penalty: 0.004\n",
      "    complexity penalty: 0.001\n"
     ]
    }
   ],
   "source": [
    "print_GOSDT_summary(model,X_train,Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 KNN Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classify(x_train,y_train,x_test_array,N=5,distance_metric = \"Euclidian\"):\n",
    "    #convert data_frames to numpy\n",
    "    x_train = x_train.to_numpy()\n",
    "    y_train = y_train.to_numpy()\n",
    "    x_test_array = x_test_array.to_numpy()\n",
    "\n",
    "    predicted_vals = np.zeros((x_test_array.shape[0],1))\n",
    "    \n",
    "    #compute distances to points\n",
    "\n",
    "    for i in range(0,x_test_array.shape[0]):\n",
    "        x_test_point = x_test_array[i,:]\n",
    "\n",
    "        if distance_metric == \"Euclidian\":\n",
    "            distances = compute_euclidian_distance(x_train,y_train,x_test_point)\n",
    "        else: # distance_metric == \"Manhattan\":\n",
    "            distances = compute_manhattan_distance(x_train,y_train,x_test_point)\n",
    "        \n",
    "        #sort distances\n",
    "        sorted_indicies = distances[:,0].argsort()\n",
    "        sorted_distances = distances[sorted_indicies[0:N]]\n",
    "        neighbor_vals = y_train[sorted_indicies[0:N]]\n",
    "\n",
    "        #determine the nearest N nearest neighbors\n",
    "        counts = np.bincount(neighbor_vals[:,0],minlength=2)\n",
    "\n",
    "        if counts[1] >= counts[0]:\n",
    "            predicted_vals[i,0] = 1\n",
    "        else:\n",
    "            predicted_vals[i,0] = 0\n",
    "\n",
    "    return predicted_vals\n",
    "\n",
    "def compute_euclidian_distance(x_train,y_train,x_test_point):\n",
    "\n",
    "    distances = np.zeros((y_train.size,1))\n",
    "\n",
    "    differences = np.subtract(x_train,x_test_point)\n",
    "    distances[:,0] = np.sum(np.square(differences),axis=1)\n",
    "\n",
    "    return distances\n",
    "\n",
    "def compute_manhattan_distance(x_train,y_train,x_test_point):\n",
    "    distances = np.zeros((y_train.size,1))\n",
    "\n",
    "    differences = np.subtract(x_train,x_test_point)\n",
    "    distances[:,0] = np.sum(np.absolute(differences),axis=1)\n",
    "\n",
    "    return distances\n",
    "\n",
    "def test_KNN(config,X,Y,X_test,Y_test,print_results = False):\n",
    "    #assuming all data has already been normalized\n",
    "    N = int(config[0])\n",
    "    distance_metric = config[1]\n",
    "    f_x = knn_classify(X,Y,X_test,N=N,distance_metric=distance_metric)\n",
    "\n",
    "    cm = compute_confusion_matrix(f_x,Y_test.to_numpy(),threshold= 0.5)\n",
    "\n",
    "    f1 = compute_F1(cm)\n",
    "    accuracy = 1 - compute_missclassification_error(cm)\n",
    "\n",
    "    if print_results:\n",
    "        print_summary_statistics(f_x,Y_test,threshold=0.5)\n",
    "    \n",
    "    return f1,accuracy\n",
    "\n",
    "def k_fold_KNN(data,test_configs,num_folds):\n",
    "    #compute the normalization constants for the full data set so that the data can be normalized\n",
    "    X = pd.DataFrame(data.iloc[:,1:])\n",
    "    normalization_constants = compute_normalization_constants(X, print_preview=False)\n",
    "    #X_normalized = normalize_data(X,normalization_constants,print_preview=False)\n",
    "\n",
    "    folds = divide_into_folds(data,num_folds)\n",
    "\n",
    "    #set asside test fold\n",
    "    test_fold = folds.pop()\n",
    "\n",
    "    #initialize variables for performing cross validation\n",
    "    validation_rounds = num_folds - 1\n",
    "    measure_results = initialize_validation_tracking(validation_rounds,test_configs)\n",
    "    features = data.columns[1:]\n",
    "\n",
    "    for round_idx in range(0,validation_rounds):\n",
    "        #reserve a validation set from the training set\n",
    "        validation_fold = folds.popleft()\n",
    "        training_sets = pd.concat(folds)\n",
    "\n",
    "        #identify inputs and outputs for training\n",
    "        X_train = pd.DataFrame(training_sets.iloc[:,1:])\n",
    "        X_train_normalized = normalize_data(X_train,normalization_constants,print_preview=False)\n",
    "        Y_train = pd.DataFrame(training_sets.iloc[:,0])\n",
    "\n",
    "        #identify inputs and outputs for validation\n",
    "        X_validation = pd.DataFrame(validation_fold.iloc[:,1:])\n",
    "        X_validation_normalized = normalize_data(X_validation,normalization_constants,print_preview=False)\n",
    "        Y_validation = pd.DataFrame(validation_fold.iloc[:,0])\n",
    "\n",
    "        #train algorithm on the rest of the training set for each K, evaluate on validation set\n",
    "        for config_idx in range(0,test_configs.shape[0]):\n",
    "            config = test_configs[config_idx]\n",
    "\n",
    "            #evaluate on validation set\n",
    "            f1,accuracy = test_KNN(config,\n",
    "            X_train_normalized,Y_train,\n",
    "            X_validation_normalized,Y_validation,print_results = False)\n",
    "\n",
    "            #record validation metric\n",
    "            measure_results.iat[round_idx,config_idx] = f1\n",
    "\n",
    "        #rotate validation fold and repeat\n",
    "        folds.append(validation_fold)\n",
    "\n",
    "    #report mean of evaluation measure for each K over the validation folds\n",
    "    result_summary,best_param = compute_mean_evaluation_metric(measure_results,test_configs,\"F1\")\n",
    "\n",
    "    txt = \"Mean results (average F1 score) of K-fold cross validation on {} folds \\n {}\".format(num_folds,result_summary)\n",
    "    print(txt)\n",
    "    #choose the best K\n",
    "\n",
    "    txt = \"Using config with N:{} and distance_metric:{}\\n\".format(best_param[0],best_param[1])\n",
    "    print(txt)\n",
    "    \n",
    "    #train on the full training set, evaluate on the test set\n",
    "    training_set = pd.concat(folds)\n",
    "    X_train = pd.DataFrame(training_set.iloc[:,1:])\n",
    "    X_train_normalized = normalize_data(X_train,normalization_constants,print_preview=False)\n",
    "    Y_train = pd.DataFrame(training_set.iloc[:,0])\n",
    "\n",
    "    \n",
    "    X_test = pd.DataFrame(test_fold.iloc[:,1:])\n",
    "    X_test_normalized = normalize_data(X_test,normalization_constants,print_preview=False)\n",
    "    Y_test = pd.DataFrame(test_fold.iloc[:,0])\n",
    "\n",
    "    #evaluate on testing set\n",
    "    f1,accuracy = test_KNN(best_param,\n",
    "            X_train_normalized,Y_train,\n",
    "            X_test_normalized,Y_test,print_results = False)\n",
    "    txt = \"\\nResults on testing fold:\\n \\tF1: {:0.2f}\\n \\tAccuracy: {:0.2f}\".format(f1,accuracy)\n",
    "    print(txt)\n",
    "\n",
    "    #return the final model\n",
    "    return best_param,normalization_constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean results (average F1 score) of K-fold cross validation on 10 folds \n",
      "     ['1' 'Euclidian']  ['3' 'Euclidian']  ['5' 'Euclidian']  \\\n",
      "F1           0.529335            0.58488           0.544718   \n",
      "\n",
      "    ['1' 'Manhattan']  ['3' 'Manhattan']  ['5' 'Manhattan']  \n",
      "F1           0.552037           0.520875           0.521905  \n",
      "Using config with N:3 and distance_metric:Euclidian\n",
      "\n",
      "\n",
      "Results on testing fold:\n",
      " \tF1: 0.72\n",
      " \tAccuracy: 0.77\n",
      "After testing on actual test set, results are as follows: \n",
      "\tF1:0.6666666666666667\n",
      "\tAccuracy:0.7033898305084746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = import_and_format_data(\"carseats_train.csv\",print_preview=False)\n",
    "X_train = pd.DataFrame(data.iloc[:,1:])\n",
    "Y_test = pd.DataFrame(data.iloc[:,0])\n",
    "\n",
    "test_configs = np.array([\n",
    "                            (1,\"Euclidian\"),\n",
    "                            (3,\"Euclidian\"),\n",
    "                            (5,\"Euclidian\"),\n",
    "                            (1,\"Manhattan\"),\n",
    "                            (3,\"Manhattan\"),\n",
    "                            (5,\"Manhattan\")])\n",
    "\n",
    "#run k-fold cross validation\n",
    "config, normalization_constants = k_fold_KNN(data,test_configs,10)\n",
    "\n",
    "data = import_and_format_data(\"carseats_test.csv\",print_preview=False)\n",
    "X_test = pd.DataFrame(data.iloc[:,1:])\n",
    "Y_test = pd.DataFrame(data.iloc[:,0])\n",
    "\n",
    "X_train_normalized = normalize_data(X_train,normalization_constants,print_preview=False)\n",
    "X_test_normalized = normalize_data(X_test,normalization_constants,print_preview=False)\n",
    "\n",
    "f1,accuracy = test_KNN(config,\n",
    "            X_train_normalized,Y_train,\n",
    "            X_test_normalized,Y_test,print_results = False)\n",
    "\n",
    "txt = \"After testing on actual test set, results are as follows: \\n\\tF1:{}\\n\\tAccuracy:{}\\n\".format(f1,accuracy)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4\n",
    "Summary of results:\n",
    "\n",
    "SKLEARN (depth of 7 using 5 fold K-fold cross validation for parameter tuning): \n",
    "    Accuracy:0.75\n",
    "    F1: 0.76\n",
    "\n",
    "GOSDT (regularization of 0.005 using 5 fold K-fold cross validation for parameter tuning): \n",
    "    Accuracy:0.75\n",
    "    F1: 0.76\n",
    "\n",
    "KNN (N = 3 with Euclidian Distance using 10 fold K-fold cross validation for parameter tuning): \n",
    "    Accuracy:0.70\n",
    "    F1: 0.66\n",
    "\n",
    "Based on the following results, it appears that SKLEARN and GOSDT did the best in my case with both achieving similar results. KNN performed similarly, but just slightly worst\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5\n",
    "The main difference between K-fold cross-validatoin and leave-one-out-cross-validation (LOOCV) is that LOOCV separates a \"test\" set that is set asside and used on each of the training iterations (i.e: only the training set and validation set rotate through the folds). This is compared to k-fold cross-validation where the testing set is also rotated for each training iterations (i.e: the training, validation, and testing set all rotate). One disadvantage of LOOCV is that the model inherently has less data to train on because it is never exposed to the data in the \"training\" set. Another disadvantage of LOOCV is that if data is imballanced and there are only a few samples of a certain class. There is a possibility that these samples may mostly fall into the \"test\" set and thus the model will never be exposed to those samples. Even if only a few of the samples fall into the \"test\" fold, it could be detrimental because the model still won't be able to train on them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6\n",
    "I think that F1 was a good evaluation metric for this data set because it provides a good balance between the precision and recall vs accuracy which only depends on the miss-classficiation rate. With that said though, for this data set, both F1 and Accuracy identified the best model and there wasn't much difference between the F1 and Accuracy statistics for the models that I trained."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a05f93782d31fb45d30263a0389582a01d7e14abf3ec6aacde92652303ee35ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
